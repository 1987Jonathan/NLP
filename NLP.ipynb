{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1987Jonathan/NLP/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ySyHoeY5z0p",
        "outputId": "5f97d85c-9e11-4081-e17c-00666abb5373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-19 03:52:28--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 3.86.22.73\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|3.86.22.73|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2024-07-19 03:52:28--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-19 03:52:29 (47.2 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 5.4.1\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.4.1\n"
          ]
        }
      ],
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing SparkNLP"
      ],
      "metadata": {
        "id": "xOWRhX9Q6B9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "from sparknlp.pretrained import PretrainedPipeline\n"
      ],
      "metadata": {
        "id": "9dxYo60w5_Rb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af46b113-c442-478c-8fc9-aa1ccfe1fcc2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = PretrainedPipeline(\"explain_document_ml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX3Def-t-CGX",
        "outputId": "64814685-c6c9-4c5c-c203-4ea566e6db5f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "explain_document_ml download started this may take some time.\n",
            "Approx size to download 9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hls = [\n",
        "    # Subject pronouns\n",
        "    \"She ran\",\n",
        "    \"He ran\",\n",
        "    \"I ran\",\n",
        "    \"We ran\",\n",
        "    \"They ran\",\n",
        "    \"You ran\",\n",
        "    \"It ran\",\n",
        "\n",
        "    # Object pronouns\n",
        "    \"I saw her\",\n",
        "    \"I saw him\",\n",
        "    \"I saw them\",\n",
        "    \"I saw us\",\n",
        "    \"I saw you\",\n",
        "    \"I saw it\",\n",
        "\n",
        "    # Possessive pronouns (used as objects)\n",
        "    \"I know her name\",\n",
        "    \"I know his name\",\n",
        "    \"I know their name\",\n",
        "    \"I know our name\",\n",
        "    \"I know your name\",\n",
        "    \"I know its name\",\n",
        "\n",
        "    # Possessive pronouns (used as subjects)\n",
        "    \"That is hers\",\n",
        "    \"That is his\",\n",
        "    \"That is theirs\",\n",
        "    \"That is ours\",\n",
        "    \"That is yours\",\n",
        "    \"That is its\",\n",
        "\n",
        "    # Reflexive pronouns\n",
        "    \"She saw herself\",\n",
        "    \"He saw himself\",\n",
        "    \"I saw myself\",\n",
        "    \"We saw ourselves\",\n",
        "    \"They saw themselves\",\n",
        "    \"You saw yourself\",\n",
        "    \"It saw itself\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "uDC93YLC-CQV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = [pipeline.annotate(hl) for hl in hls]"
      ],
      "metadata": {
        "id": "iPMDmrar-S6C"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-RBlgQV9-S_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aceaebde-5968-4d14-8583-849f6c98c7a5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'document': ['She ran'],\n",
              "  'spell': ['She', 'ran'],\n",
              "  'pos': ['PRP', 'VBD'],\n",
              "  'lemmas': ['She', 'run'],\n",
              "  'token': ['She', 'ran'],\n",
              "  'stems': ['she', 'ran'],\n",
              "  'sentence': ['She ran']},\n",
              " {'document': ['He ran'],\n",
              "  'spell': ['He', 'ran'],\n",
              "  'pos': ['PRP', 'VBD'],\n",
              "  'lemmas': ['He', 'run'],\n",
              "  'token': ['He', 'ran'],\n",
              "  'stems': ['he', 'ran'],\n",
              "  'sentence': ['He ran']},\n",
              " {'document': ['I ran'],\n",
              "  'spell': ['I', 'ran'],\n",
              "  'pos': ['PRP', 'VBD'],\n",
              "  'lemmas': ['I', 'run'],\n",
              "  'token': ['I', 'ran'],\n",
              "  'stems': ['i', 'ran'],\n",
              "  'sentence': ['I ran']},\n",
              " {'document': ['We ran'],\n",
              "  'spell': ['We', 'ran'],\n",
              "  'pos': ['PRP', 'VBD'],\n",
              "  'lemmas': ['We', 'run'],\n",
              "  'token': ['We', 'ran'],\n",
              "  'stems': ['we', 'ran'],\n",
              "  'sentence': ['We ran']},\n",
              " {'document': ['They ran'],\n",
              "  'spell': ['They', 'ran'],\n",
              "  'pos': ['PRP', 'VBD'],\n",
              "  'lemmas': ['They', 'run'],\n",
              "  'token': ['They', 'ran'],\n",
              "  'stems': ['thei', 'ran'],\n",
              "  'sentence': ['They ran']},\n",
              " {'document': ['You ran'],\n",
              "  'spell': ['You', 'ran'],\n",
              "  'pos': ['PRP', 'VBD'],\n",
              "  'lemmas': ['You', 'run'],\n",
              "  'token': ['You', 'ran'],\n",
              "  'stems': ['you', 'ran'],\n",
              "  'sentence': ['You ran']},\n",
              " {'document': ['It ran'],\n",
              "  'spell': ['It', 'ran'],\n",
              "  'pos': ['PRP', 'VBD'],\n",
              "  'lemmas': ['It', 'run'],\n",
              "  'token': ['It', 'ran'],\n",
              "  'stems': ['it', 'ran'],\n",
              "  'sentence': ['It ran']},\n",
              " {'document': ['I saw her'],\n",
              "  'spell': ['I', 'saw', 'her'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP$'],\n",
              "  'lemmas': ['I', 'see', 'she'],\n",
              "  'token': ['I', 'saw', 'her'],\n",
              "  'stems': ['i', 'saw', 'her'],\n",
              "  'sentence': ['I saw her']},\n",
              " {'document': ['I saw him'],\n",
              "  'spell': ['I', 'saw', 'him'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['I', 'see', 'he'],\n",
              "  'token': ['I', 'saw', 'him'],\n",
              "  'stems': ['i', 'saw', 'him'],\n",
              "  'sentence': ['I saw him']},\n",
              " {'document': ['I saw them'],\n",
              "  'spell': ['I', 'saw', 'them'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['I', 'see', 'they'],\n",
              "  'token': ['I', 'saw', 'them'],\n",
              "  'stems': ['i', 'saw', 'them'],\n",
              "  'sentence': ['I saw them']},\n",
              " {'document': ['I saw us'],\n",
              "  'spell': ['I', 'saw', 'us'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['I', 'see', 'we'],\n",
              "  'token': ['I', 'saw', 'us'],\n",
              "  'stems': ['i', 'saw', 'u'],\n",
              "  'sentence': ['I saw us']},\n",
              " {'document': ['I saw you'],\n",
              "  'spell': ['I', 'saw', 'you'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['I', 'see', 'you'],\n",
              "  'token': ['I', 'saw', 'you'],\n",
              "  'stems': ['i', 'saw', 'you'],\n",
              "  'sentence': ['I saw you']},\n",
              " {'document': ['I saw it'],\n",
              "  'spell': ['I', 'saw', 'it'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['I', 'see', 'it'],\n",
              "  'token': ['I', 'saw', 'it'],\n",
              "  'stems': ['i', 'saw', 'it'],\n",
              "  'sentence': ['I saw it']},\n",
              " {'document': ['I know her name'],\n",
              "  'spell': ['I', 'know', 'her', 'name'],\n",
              "  'pos': ['PRP', 'VBP', 'PRP', 'NN'],\n",
              "  'lemmas': ['I', 'know', 'she', 'name'],\n",
              "  'token': ['I', 'know', 'her', 'name'],\n",
              "  'stems': ['i', 'know', 'her', 'name'],\n",
              "  'sentence': ['I know her name']},\n",
              " {'document': ['I know his name'],\n",
              "  'spell': ['I', 'know', 'his', 'name'],\n",
              "  'pos': ['PRP', 'VBP', 'PRP$', 'NN'],\n",
              "  'lemmas': ['I', 'know', 'he', 'name'],\n",
              "  'token': ['I', 'know', 'his', 'name'],\n",
              "  'stems': ['i', 'know', 'hi', 'name'],\n",
              "  'sentence': ['I know his name']},\n",
              " {'document': ['I know their name'],\n",
              "  'spell': ['I', 'know', 'their', 'name'],\n",
              "  'pos': ['PRP', 'VBP', 'PRP$', 'NN'],\n",
              "  'lemmas': ['I', 'know', 'they', 'name'],\n",
              "  'token': ['I', 'know', 'their', 'name'],\n",
              "  'stems': ['i', 'know', 'their', 'name'],\n",
              "  'sentence': ['I know their name']},\n",
              " {'document': ['I know our name'],\n",
              "  'spell': ['I', 'know', 'our', 'name'],\n",
              "  'pos': ['PRP', 'VBP', 'PRP$', 'NN'],\n",
              "  'lemmas': ['I', 'know', 'we', 'name'],\n",
              "  'token': ['I', 'know', 'our', 'name'],\n",
              "  'stems': ['i', 'know', 'our', 'name'],\n",
              "  'sentence': ['I know our name']},\n",
              " {'document': ['I know your name'],\n",
              "  'spell': ['I', 'know', 'your', 'name'],\n",
              "  'pos': ['PRP', 'VBP', 'PRP$', 'NN'],\n",
              "  'lemmas': ['I', 'know', 'you', 'name'],\n",
              "  'token': ['I', 'know', 'your', 'name'],\n",
              "  'stems': ['i', 'know', 'your', 'name'],\n",
              "  'sentence': ['I know your name']},\n",
              " {'document': ['I know its name'],\n",
              "  'spell': ['I', 'know', 'its', 'name'],\n",
              "  'pos': ['PRP', 'VBP', 'PRP$', 'NN'],\n",
              "  'lemmas': ['I', 'know', 'it', 'name'],\n",
              "  'token': ['I', 'know', 'its', 'name'],\n",
              "  'stems': ['i', 'know', 'it', 'name'],\n",
              "  'sentence': ['I know its name']},\n",
              " {'document': ['That is hers'],\n",
              "  'spell': ['That', 'is', 'hers'],\n",
              "  'pos': ['DT', 'VBZ', 'NNS'],\n",
              "  'lemmas': ['That', 'be', 'hers'],\n",
              "  'token': ['That', 'is', 'hers'],\n",
              "  'stems': ['that', 'i', 'her'],\n",
              "  'sentence': ['That is hers']},\n",
              " {'document': ['That is his'],\n",
              "  'spell': ['That', 'is', 'his'],\n",
              "  'pos': ['DT', 'VBZ', 'PRP$'],\n",
              "  'lemmas': ['That', 'be', 'he'],\n",
              "  'token': ['That', 'is', 'his'],\n",
              "  'stems': ['that', 'i', 'hi'],\n",
              "  'sentence': ['That is his']},\n",
              " {'document': ['That is theirs'],\n",
              "  'spell': ['That', 'is', 'theirs'],\n",
              "  'pos': ['DT', 'VBZ', 'NNS'],\n",
              "  'lemmas': ['That', 'be', 'theirs'],\n",
              "  'token': ['That', 'is', 'theirs'],\n",
              "  'stems': ['that', 'i', 'their'],\n",
              "  'sentence': ['That is theirs']},\n",
              " {'document': ['That is ours'],\n",
              "  'spell': ['That', 'is', 'ours'],\n",
              "  'pos': ['DT', 'VBZ', 'NNS'],\n",
              "  'lemmas': ['That', 'be', 'ours'],\n",
              "  'token': ['That', 'is', 'ours'],\n",
              "  'stems': ['that', 'i', 'our'],\n",
              "  'sentence': ['That is ours']},\n",
              " {'document': ['That is yours'],\n",
              "  'spell': ['That', 'is', 'yours'],\n",
              "  'pos': ['DT', 'VBZ', 'NNS'],\n",
              "  'lemmas': ['That', 'be', 'yours'],\n",
              "  'token': ['That', 'is', 'yours'],\n",
              "  'stems': ['that', 'i', 'your'],\n",
              "  'sentence': ['That is yours']},\n",
              " {'document': ['That is its'],\n",
              "  'spell': ['That', 'is', 'its'],\n",
              "  'pos': ['DT', 'VBZ', 'PRP$'],\n",
              "  'lemmas': ['That', 'be', 'it'],\n",
              "  'token': ['That', 'is', 'its'],\n",
              "  'stems': ['that', 'i', 'it'],\n",
              "  'sentence': ['That is its']},\n",
              " {'document': ['She saw herself'],\n",
              "  'spell': ['She', 'saw', 'herself'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['She', 'see', 'herself'],\n",
              "  'token': ['She', 'saw', 'herself'],\n",
              "  'stems': ['she', 'saw', 'herself'],\n",
              "  'sentence': ['She saw herself']},\n",
              " {'document': ['He saw himself'],\n",
              "  'spell': ['He', 'saw', 'himself'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['He', 'see', 'himself'],\n",
              "  'token': ['He', 'saw', 'himself'],\n",
              "  'stems': ['he', 'saw', 'himself'],\n",
              "  'sentence': ['He saw himself']},\n",
              " {'document': ['I saw myself'],\n",
              "  'spell': ['I', 'saw', 'myself'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['I', 'see', 'myself'],\n",
              "  'token': ['I', 'saw', 'myself'],\n",
              "  'stems': ['i', 'saw', 'myself'],\n",
              "  'sentence': ['I saw myself']},\n",
              " {'document': ['We saw ourselves'],\n",
              "  'spell': ['We', 'saw', 'ourselves'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['We', 'see', 'ourselves'],\n",
              "  'token': ['We', 'saw', 'ourselves'],\n",
              "  'stems': ['we', 'saw', 'ourselv'],\n",
              "  'sentence': ['We saw ourselves']},\n",
              " {'document': ['They saw themselves'],\n",
              "  'spell': ['They', 'saw', 'themselves'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['They', 'see', 'themselves'],\n",
              "  'token': ['They', 'saw', 'themselves'],\n",
              "  'stems': ['thei', 'saw', 'themselv'],\n",
              "  'sentence': ['They saw themselves']},\n",
              " {'document': ['You saw yourself'],\n",
              "  'spell': ['You', 'saw', 'yourself'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['You', 'see', 'yourself'],\n",
              "  'token': ['You', 'saw', 'yourself'],\n",
              "  'stems': ['you', 'saw', 'yourself'],\n",
              "  'sentence': ['You saw yourself']},\n",
              " {'document': ['It saw itself'],\n",
              "  'spell': ['It', 'saw', 'itself'],\n",
              "  'pos': ['PRP', 'VBD', 'PRP'],\n",
              "  'lemmas': ['It', 'see', 'itself'],\n",
              "  'token': ['It', 'saw', 'itself'],\n",
              "  'stems': ['it', 'saw', 'itself'],\n",
              "  'sentence': ['It saw itself']}]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tok_tag = [(df['token'],df['pos']) for df in dfs]"
      ],
      "metadata": {
        "id": "ali61V58-TCl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok_tag"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZNJPfHY8-TFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf37319-4d74-4ab8-ee8e-83a684095e27"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['She', 'ran'], ['PRP', 'VBD']),\n",
              " (['He', 'ran'], ['PRP', 'VBD']),\n",
              " (['I', 'ran'], ['PRP', 'VBD']),\n",
              " (['We', 'ran'], ['PRP', 'VBD']),\n",
              " (['They', 'ran'], ['PRP', 'VBD']),\n",
              " (['You', 'ran'], ['PRP', 'VBD']),\n",
              " (['It', 'ran'], ['PRP', 'VBD']),\n",
              " (['I', 'saw', 'her'], ['PRP', 'VBD', 'PRP$']),\n",
              " (['I', 'saw', 'him'], ['PRP', 'VBD', 'PRP']),\n",
              " (['I', 'saw', 'them'], ['PRP', 'VBD', 'PRP']),\n",
              " (['I', 'saw', 'us'], ['PRP', 'VBD', 'PRP']),\n",
              " (['I', 'saw', 'you'], ['PRP', 'VBD', 'PRP']),\n",
              " (['I', 'saw', 'it'], ['PRP', 'VBD', 'PRP']),\n",
              " (['I', 'know', 'her', 'name'], ['PRP', 'VBP', 'PRP', 'NN']),\n",
              " (['I', 'know', 'his', 'name'], ['PRP', 'VBP', 'PRP$', 'NN']),\n",
              " (['I', 'know', 'their', 'name'], ['PRP', 'VBP', 'PRP$', 'NN']),\n",
              " (['I', 'know', 'our', 'name'], ['PRP', 'VBP', 'PRP$', 'NN']),\n",
              " (['I', 'know', 'your', 'name'], ['PRP', 'VBP', 'PRP$', 'NN']),\n",
              " (['I', 'know', 'its', 'name'], ['PRP', 'VBP', 'PRP$', 'NN']),\n",
              " (['That', 'is', 'hers'], ['DT', 'VBZ', 'NNS']),\n",
              " (['That', 'is', 'his'], ['DT', 'VBZ', 'PRP$']),\n",
              " (['That', 'is', 'theirs'], ['DT', 'VBZ', 'NNS']),\n",
              " (['That', 'is', 'ours'], ['DT', 'VBZ', 'NNS']),\n",
              " (['That', 'is', 'yours'], ['DT', 'VBZ', 'NNS']),\n",
              " (['That', 'is', 'its'], ['DT', 'VBZ', 'PRP$']),\n",
              " (['She', 'saw', 'herself'], ['PRP', 'VBD', 'PRP']),\n",
              " (['He', 'saw', 'himself'], ['PRP', 'VBD', 'PRP']),\n",
              " (['I', 'saw', 'myself'], ['PRP', 'VBD', 'PRP']),\n",
              " (['We', 'saw', 'ourselves'], ['PRP', 'VBD', 'PRP']),\n",
              " (['They', 'saw', 'themselves'], ['PRP', 'VBD', 'PRP']),\n",
              " (['You', 'saw', 'yourself'], ['PRP', 'VBD', 'PRP']),\n",
              " (['It', 'saw', 'itself'], ['PRP', 'VBD', 'PRP'])]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zips = [list(zip(tt[0], tt[1])) for tt in tok_tag]"
      ],
      "metadata": {
        "id": "7YP4COs7-TIJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zips"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RMVhLbF--TKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf54dc2-9fc3-4fce-8dd1-f460bdc61105"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('She', 'PRP'), ('ran', 'VBD')],\n",
              " [('He', 'PRP'), ('ran', 'VBD')],\n",
              " [('I', 'PRP'), ('ran', 'VBD')],\n",
              " [('We', 'PRP'), ('ran', 'VBD')],\n",
              " [('They', 'PRP'), ('ran', 'VBD')],\n",
              " [('You', 'PRP'), ('ran', 'VBD')],\n",
              " [('It', 'PRP'), ('ran', 'VBD')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('her', 'PRP$')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('him', 'PRP')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('them', 'PRP')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('us', 'PRP')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('you', 'PRP')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('it', 'PRP')],\n",
              " [('I', 'PRP'), ('know', 'VBP'), ('her', 'PRP'), ('name', 'NN')],\n",
              " [('I', 'PRP'), ('know', 'VBP'), ('his', 'PRP$'), ('name', 'NN')],\n",
              " [('I', 'PRP'), ('know', 'VBP'), ('their', 'PRP$'), ('name', 'NN')],\n",
              " [('I', 'PRP'), ('know', 'VBP'), ('our', 'PRP$'), ('name', 'NN')],\n",
              " [('I', 'PRP'), ('know', 'VBP'), ('your', 'PRP$'), ('name', 'NN')],\n",
              " [('I', 'PRP'), ('know', 'VBP'), ('its', 'PRP$'), ('name', 'NN')],\n",
              " [('That', 'DT'), ('is', 'VBZ'), ('hers', 'NNS')],\n",
              " [('That', 'DT'), ('is', 'VBZ'), ('his', 'PRP$')],\n",
              " [('That', 'DT'), ('is', 'VBZ'), ('theirs', 'NNS')],\n",
              " [('That', 'DT'), ('is', 'VBZ'), ('ours', 'NNS')],\n",
              " [('That', 'DT'), ('is', 'VBZ'), ('yours', 'NNS')],\n",
              " [('That', 'DT'), ('is', 'VBZ'), ('its', 'PRP$')],\n",
              " [('She', 'PRP'), ('saw', 'VBD'), ('herself', 'PRP')],\n",
              " [('He', 'PRP'), ('saw', 'VBD'), ('himself', 'PRP')],\n",
              " [('I', 'PRP'), ('saw', 'VBD'), ('myself', 'PRP')],\n",
              " [('We', 'PRP'), ('saw', 'VBD'), ('ourselves', 'PRP')],\n",
              " [('They', 'PRP'), ('saw', 'VBD'), ('themselves', 'PRP')],\n",
              " [('You', 'PRP'), ('saw', 'VBD'), ('yourself', 'PRP')],\n",
              " [('It', 'PRP'), ('saw', 'VBD'), ('itself', 'PRP')]]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged = [\" \".join([\"\".join(word) for word in hl]) for hl in zips]"
      ],
      "metadata": {
        "id": "au6F0pax-TNK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yQ6H_r41-TQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dcf744-f427-448c-983e-9a574b70f470"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ShePRP ranVBD',\n",
              " 'HePRP ranVBD',\n",
              " 'IPRP ranVBD',\n",
              " 'WePRP ranVBD',\n",
              " 'TheyPRP ranVBD',\n",
              " 'YouPRP ranVBD',\n",
              " 'ItPRP ranVBD',\n",
              " 'IPRP sawVBD herPRP$',\n",
              " 'IPRP sawVBD himPRP',\n",
              " 'IPRP sawVBD themPRP',\n",
              " 'IPRP sawVBD usPRP',\n",
              " 'IPRP sawVBD youPRP',\n",
              " 'IPRP sawVBD itPRP',\n",
              " 'IPRP knowVBP herPRP nameNN',\n",
              " 'IPRP knowVBP hisPRP$ nameNN',\n",
              " 'IPRP knowVBP theirPRP$ nameNN',\n",
              " 'IPRP knowVBP ourPRP$ nameNN',\n",
              " 'IPRP knowVBP yourPRP$ nameNN',\n",
              " 'IPRP knowVBP itsPRP$ nameNN',\n",
              " 'ThatDT isVBZ hersNNS',\n",
              " 'ThatDT isVBZ hisPRP$',\n",
              " 'ThatDT isVBZ theirsNNS',\n",
              " 'ThatDT isVBZ oursNNS',\n",
              " 'ThatDT isVBZ yoursNNS',\n",
              " 'ThatDT isVBZ itsPRP$',\n",
              " 'ShePRP sawVBD herselfPRP',\n",
              " 'HePRP sawVBD himselfPRP',\n",
              " 'IPRP sawVBD myselfPRP',\n",
              " 'WePRP sawVBD ourselvesPRP',\n",
              " 'TheyPRP sawVBD themselvesPRP',\n",
              " 'YouPRP sawVBD yourselfPRP',\n",
              " 'ItPRP sawVBD itselfPRP']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://www.gutenberg.org/cache/epub/2701/pg2701.txt\" -o mobydick.txt"
      ],
      "metadata": {
        "id": "A1r2Zowj-fn0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "799cf9bc-1f52-4afe-9ea3-169050664811"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1246k  100 1246k    0     0   502k      0  0:00:02  0:00:02 --:--:--  502k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobydick = open('mobydick.txt').read()"
      ],
      "metadata": {
        "id": "9iknDpCz-fqO"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mobydick[:1000])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W5tnBx_a-fsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93f885c-9dcc-4e7a-dcc2-811e35208c1b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of Moby Dick; Or, The Whale\n",
            "    \n",
            "This ebook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this ebook or online\n",
            "at www.gutenberg.org. If you are not located in the United States,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this eBook.\n",
            "\n",
            "Title: Moby Dick; Or, The Whale\n",
            "\n",
            "Author: Herman Melville\n",
            "\n",
            "Release date: July 1, 2001 [eBook #2701]\n",
            "                Most recently updated: August 18, 2021\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: Daniel Lazarus, Jonesey, and David Widger\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK MOBY DICK; OR, THE WHALE ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "MOBY-DICK;\n",
            "\n",
            "or, THE WHALE.\n",
            "\n",
            "By Herman Melville\n",
            "\n",
            "\n",
            "\n",
            "CONTENTS\n",
            "\n",
            "ETYMOLOGY.\n",
            "\n",
            "EXTRACTS (Supplied by a Sub-Sub-Librarian).\n",
            "\n",
            "CHAPTER 1. Loomings.\n",
            "\n",
            "CHAPTER 2. The Carpet-Bag.\n",
            "\n",
            "CHAPTER 3. The Spouter-Inn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.annotate(mobydick[:100])['pos']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eCzIAM61-fux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72880403-aa2a-48a8-9152-5b1912ba1fa9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DT',\n",
              " 'NNP',\n",
              " 'NNP',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'NN',\n",
              " 'NNP',\n",
              " ':',\n",
              " 'CC',\n",
              " ',',\n",
              " 'DT',\n",
              " 'NNP',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'VBZ',\n",
              " 'IN',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'NN',\n",
              " 'DT']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"demo\").getOrCreate()"
      ],
      "metadata": {
        "id": "VO8a5HB3-fw3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobydick = spark.sparkContext.textFile('mobydick.txt')\n",
        "\n",
        "counts = (\n",
        "    mobydick.flatMap(lambda line: line.split(\" \"))\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")"
      ],
      "metadata": {
        "id": "e2CJ9usZ-fzh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts.collect()[:10]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s_SaSrVZ-f17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab4b7af-3a3b-47fe-ef59-29e633a42554"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 634),\n",
              " ('Project', 80),\n",
              " ('of', 6642),\n",
              " ('Moby', 79),\n",
              " ('', 4320),\n",
              " ('ebook', 2),\n",
              " ('is', 1585),\n",
              " ('use', 36),\n",
              " ('anyone', 5),\n",
              " ('anywhere', 11)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://www.gutenberg.org/cache/epub/37106/pg37106.txt\" -o littlewomen.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TxXm5e8P-f4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee9ab15-872e-42a9-dd9e-62979efd90fd"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1087k  100 1087k    0     0   540k      0  0:00:02  0:00:02 --:--:--  540k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "littlewomen = open('littlewomen.txt').read()"
      ],
      "metadata": {
        "id": "gO7LEU6a-f6W"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(littlewomen[:1000])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "h2UOQocF-f8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e07db0-07ad-470b-c749-9df574af2135"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of Little Women; Or, Meg, Jo, Beth, and Amy\n",
            "    \n",
            "This ebook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this ebook or online\n",
            "at www.gutenberg.org. If you are not located in the United States,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this eBook.\n",
            "\n",
            "Title: Little Women; Or, Meg, Jo, Beth, and Amy\n",
            "\n",
            "Author: Louisa May Alcott\n",
            "\n",
            "Illustrator: Frank T. Merrill\n",
            "\n",
            "Release date: August 16, 2011 [eBook #37106]\n",
            "                Most recently updated: May 22, 2023\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: David Edwards, Ernest Schaal, Robert Homa, and the Online Distributed Proofreading Team\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK LITTLE WOMEN; OR, MEG, JO, BETH, AND AMY ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                      [Illustration: LITTLE WOMEN\n",
            "               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.annotate(littlewomen[:100])['pos']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6ml3PtCH-f-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e76d043-6b8a-480e-9526-436978e62265"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DT',\n",
              " 'NNP',\n",
              " 'NNP',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'NNP',\n",
              " 'NNP',\n",
              " ':',\n",
              " 'CC',\n",
              " ',',\n",
              " 'NNP',\n",
              " ',',\n",
              " 'NNP',\n",
              " ',',\n",
              " 'NNP',\n",
              " ',',\n",
              " 'CC',\n",
              " 'NNP',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'VBZ',\n",
              " 'IN',\n",
              " 'DT']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"demo\").getOrCreate()"
      ],
      "metadata": {
        "id": "KqR_BMcIEKov"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "littlewomen = spark.sparkContext.textFile('littlewomen.txt')\n",
        "\n",
        "counts_lw = (\n",
        "    littlewomen.flatMap(lambda line: line.split(\" \"))\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")"
      ],
      "metadata": {
        "id": "5df9vFfQEKrI"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts_lw.collect()[:10]"
      ],
      "metadata": {
        "id": "Rltl4jDiEKtc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c57f2917-4b82-4e0e-88a4-b2bf9c4374ae"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 341),\n",
              " ('Project', 82),\n",
              " ('of', 3622),\n",
              " ('Women;', 3),\n",
              " ('Jo,', 406),\n",
              " ('Amy', 356),\n",
              " ('', 24604),\n",
              " ('ebook', 2),\n",
              " ('is', 758),\n",
              " ('use', 54)]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://www.gutenberg.org/files/1342/1342-0.txt\" -o littlemen.txt"
      ],
      "metadata": {
        "id": "dDOpN_f-EKv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb4136c-1604-44cc-a1c1-d7e67a2b2069"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  734k  100  734k    0     0   330k      0  0:00:02  0:00:02 --:--:--  330k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "littlemen = open('littlemen.txt').read()"
      ],
      "metadata": {
        "id": "fbBPVXbyIg_u"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(littlemen[:10000])"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVio5y0jIhCe",
        "outputId": "68ec9779-097e-4121-9159-8e8998a8db80"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** START OF THE PROJECT GUTENBERG EBOOK 1342 ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            [Illustration:\n",
            "\n",
            "                             GEORGE ALLEN\n",
            "                               PUBLISHER\n",
            "\n",
            "                        156 CHARING CROSS ROAD\n",
            "                                LONDON\n",
            "\n",
            "                             RUSKIN HOUSE\n",
            "                                   ]\n",
            "\n",
            "                            [Illustration:\n",
            "\n",
            "               _Reading Jane’s Letters._      _Chap 34._\n",
            "                                   ]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                PRIDE.\n",
            "                                  and\n",
            "                               PREJUDICE\n",
            "\n",
            "                                  by\n",
            "                             Jane Austen,\n",
            "\n",
            "                           with a Preface by\n",
            "                           George Saintsbury\n",
            "                                  and\n",
            "                           Illustrations by\n",
            "                             Hugh Thomson\n",
            "\n",
            "                         [Illustration: 1894]\n",
            "\n",
            "                       Ruskin       156. Charing\n",
            "                       House.        Cross Road.\n",
            "\n",
            "                                London\n",
            "                             George Allen.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "             CHISWICK PRESS:--CHARLES WHITTINGHAM AND CO.\n",
            "                  TOOKS COURT, CHANCERY LANE, LONDON.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            [Illustration:\n",
            "\n",
            "                          _To J. Comyns Carr\n",
            "                      in acknowledgment of all I\n",
            "                       owe to his friendship and\n",
            "                    advice, these illustrations are\n",
            "                         gratefully inscribed_\n",
            "\n",
            "                            _Hugh Thomson_\n",
            "                                   ]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "PREFACE.\n",
            "\n",
            "[Illustration]\n",
            "\n",
            "\n",
            "_Walt Whitman has somewhere a fine and just distinction between “loving\n",
            "by allowance” and “loving with personal love.” This distinction applies\n",
            "to books as well as to men and women; and in the case of the not very\n",
            "numerous authors who are the objects of the personal affection, it\n",
            "brings a curious consequence with it. There is much more difference as\n",
            "to their best work than in the case of those others who are loved “by\n",
            "allowance” by convention, and because it is felt to be the right and\n",
            "proper thing to love them. And in the sect--fairly large and yet\n",
            "unusually choice--of Austenians or Janites, there would probably be\n",
            "found partisans of the claim to primacy of almost every one of the\n",
            "novels. To some the delightful freshness and humour of_ Northanger\n",
            "Abbey, _its completeness, finish, and_ entrain, _obscure the undoubted\n",
            "critical facts that its scale is small, and its scheme, after all, that\n",
            "of burlesque or parody, a kind in which the first rank is reached with\n",
            "difficulty._ Persuasion, _relatively faint in tone, and not enthralling\n",
            "in interest, has devotees who exalt above all the others its exquisite\n",
            "delicacy and keeping. The catastrophe of_ Mansfield Park _is admittedly\n",
            "theatrical, the hero and heroine are insipid, and the author has almost\n",
            "wickedly destroyed all romantic interest by expressly admitting that\n",
            "Edmund only took Fanny because Mary shocked him, and that Fanny might\n",
            "very likely have taken Crawford if he had been a little more assiduous;\n",
            "yet the matchless rehearsal-scenes and the characters of Mrs. Norris and\n",
            "others have secured, I believe, a considerable party for it._ Sense and\n",
            "Sensibility _has perhaps the fewest out-and-out admirers; but it does\n",
            "not want them._\n",
            "\n",
            "_I suppose, however, that the majority of at least competent votes\n",
            "would, all things considered, be divided between_ Emma _and the present\n",
            "book; and perhaps the vulgar verdict (if indeed a fondness for Miss\n",
            "Austen be not of itself a patent of exemption from any possible charge\n",
            "of vulgarity) would go for_ Emma. _It is the larger, the more varied, the\n",
            "more popular; the author had by the time of its composition seen rather\n",
            "more of the world, and had improved her general, though not her most\n",
            "peculiar and characteristic dialogue; such figures as Miss Bates, as the\n",
            "Eltons, cannot but unite the suffrages of everybody. On the other hand,\n",
            "I, for my part, declare for_ Pride and Prejudice _unhesitatingly. It\n",
            "seems to me the most perfect, the most characteristic, the most\n",
            "eminently quintessential of its author’s works; and for this contention\n",
            "in such narrow space as is permitted to me, I propose here to show\n",
            "cause._\n",
            "\n",
            "_In the first place, the book (it may be barely necessary to remind the\n",
            "reader) was in its first shape written very early, somewhere about 1796,\n",
            "when Miss Austen was barely twenty-one; though it was revised and\n",
            "finished at Chawton some fifteen years later, and was not published till\n",
            "1813, only four years before her death. I do not know whether, in this\n",
            "combination of the fresh and vigorous projection of youth, and the\n",
            "critical revision of middle life, there may be traced the distinct\n",
            "superiority in point of construction, which, as it seems to me, it\n",
            "possesses over all the others. The plot, though not elaborate, is almost\n",
            "regular enough for Fielding; hardly a character, hardly an incident\n",
            "could be retrenched without loss to the story. The elopement of Lydia\n",
            "and Wickham is not, like that of Crawford and Mrs. Rushworth, a_ coup de\n",
            "théâtre; _it connects itself in the strictest way with the course of the\n",
            "story earlier, and brings about the denouement with complete propriety.\n",
            "All the minor passages--the loves of Jane and Bingley, the advent of Mr.\n",
            "Collins, the visit to Hunsford, the Derbyshire tour--fit in after the\n",
            "same unostentatious, but masterly fashion. There is no attempt at the\n",
            "hide-and-seek, in-and-out business, which in the transactions between\n",
            "Frank Churchill and Jane Fairfax contributes no doubt a good deal to the\n",
            "intrigue of_ Emma, _but contributes it in a fashion which I do not think\n",
            "the best feature of that otherwise admirable book. Although Miss Austen\n",
            "always liked something of the misunderstanding kind, which afforded her\n",
            "opportunities for the display of the peculiar and incomparable talent to\n",
            "be noticed presently, she has been satisfied here with the perfectly\n",
            "natural occasions provided by the false account of Darcy’s conduct given\n",
            "by Wickham, and by the awkwardness (arising with equal naturalness) from\n",
            "the gradual transformation of Elizabeth’s own feelings from positive\n",
            "aversion to actual love. I do not know whether the all-grasping hand of\n",
            "the playwright has ever been laid upon_ Pride and Prejudice; _and I dare\n",
            "say that, if it were, the situations would prove not startling or\n",
            "garish enough for the footlights, the character-scheme too subtle and\n",
            "delicate for pit and gallery. But if the attempt were made, it would\n",
            "certainly not be hampered by any of those loosenesses of construction,\n",
            "which, sometimes disguised by the conveniences of which the novelist can\n",
            "avail himself, appear at once on the stage._\n",
            "\n",
            "_I think, however, though the thought will doubtless seem heretical to\n",
            "more than one school of critics, that construction is not the highest\n",
            "merit, the choicest gift, of the novelist. It sets off his other gifts\n",
            "and graces most advantageously to the critical eye; and the want of it\n",
            "will sometimes mar those graces--appreciably, though not quite\n",
            "consciously--to eyes by no means ultra-critical. But a very badly-built\n",
            "novel which excelled in pathetic or humorous character, or which\n",
            "displayed consummate command of dialogue--perhaps the rarest of all\n",
            "faculties--would be an infinitely better thing than a faultless plot\n",
            "acted and told by puppets with pebbles in their mouths. And despite the\n",
            "ability which Miss Austen has shown in working out the story, I for one\n",
            "should put_ Pride and Prejudice _far lower if it did not contain what\n",
            "seem to me the very masterpieces of Miss Austen’s humour and of her\n",
            "faculty of character-creation--masterpieces who may indeed admit John\n",
            "Thorpe, the Eltons, Mrs. Norris, and one or two others to their company,\n",
            "but who, in one instance certainly, and perhaps in others, are still\n",
            "superior to them._\n",
            "\n",
            "_The characteristics of Miss Austen’s humour are so subtle and delicate\n",
            "that they are, perhaps, at all times easier to apprehend than to\n",
            "express, and at any particular time likely to be differently\n",
            "apprehended by different persons. To me this humour seems to possess a\n",
            "greater affinity, on the whole, to that of Addison than to any other of\n",
            "the numerous species of this great British genus. The differences of\n",
            "scheme, of time, of subject, of literary convention, are, of course,\n",
            "obvious enough; the difference of sex does not, perhaps, count for much,\n",
            "for there was a distinctly feminine element in “Mr. Spectator,” and in\n",
            "Jane Austen’s genius there was, though nothing mannish, much that was\n",
            "masculine. But the likeness of quality consists in a great number of\n",
            "common subdivisions of quality--demureness, extreme minuteness of touch,\n",
            "avoidance of loud tones and glaring effects. Also there is in both a\n",
            "certain not inhuman or unamiable cruelty. It is the custom with those\n",
            "who judge grossly to contrast the good nature of Addison with the\n",
            "savagery of Swift, the mildness of Miss Austen with the boisterousness\n",
            "of Fielding and Smollett, even with the ferocious practical jokes that\n",
            "her immediate predecessor, Miss Burney, allowed without very much\n",
            "protest. Yet, both in Mr. Addison and in Miss Austen there is, though a\n",
            "restrained and well-mannered, an insatiable and ruthless delight in\n",
            "roasting and cutting up a fool. A man in the early eighteenth century,\n",
            "of course, could push this taste further than a lady in the early\n",
            "nineteenth; and no doubt Miss Austen’s principles, as well as her heart,\n",
            "would have shrunk from such things as the letter from the unfortunate\n",
            "husband in the_ Spectator, _who describes, with all the gusto and all the\n",
            "innocence in the world, how his wife and his friend induce him to play\n",
            "at blind-man’s-buff. But another_ Spectator _letter--that of the damsel\n",
            "of fourteen who wishes to marry Mr. Shapely, and assures her selected\n",
            "Mentor that “he admires your_ Spectators _mightily”--might have been\n",
            "written by a rather more ladylike and intelligent Lydia Bennet in the\n",
            "days of Lydia’s great-grandmother; while, on \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.annotate(littlemen[:100])['pos']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS4KIPPWIhEd",
        "outputId": "286a6b0c-5dc4-4523-da11-2a100a452ad4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NN', 'NNP', 'IN', 'DT', 'NNP', 'NNP', 'NNP', 'CD', 'NN', 'NNP', ':']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"demo\").getOrCreate()"
      ],
      "metadata": {
        "id": "rCdiEhjfIhGk"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "littlemen = spark.sparkContext.textFile('littlemen.txt')\n",
        "\n",
        "counts_lm = (\n",
        "    littlemen.flatMap(lambda line: line.split(\" \"))\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")\n"
      ],
      "metadata": {
        "id": "yNbvK4lhIhI3"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts_lm.collect()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QDkZ8O3IhLG",
        "outputId": "24c83003-09e5-480c-e0e0-54de3c384b6c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('***', 4),\n",
              " ('OF', 2),\n",
              " ('GUTENBERG', 2),\n",
              " ('1342', 2),\n",
              " ('', 10282),\n",
              " ('ALLEN', 1),\n",
              " ('ROAD', 1),\n",
              " ('RUSKIN', 1),\n",
              " ('_Reading', 1),\n",
              " ('Jane’s', 27)]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "import sparknlp\n",
        "from pyspark.sql.functions import col, explode, split\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Pronoun Frequency Analysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Initialize Spark NLP\n",
        "sparknlp.start()\n",
        "\n",
        "# Load the text of Moby Dick\n",
        "!curl \"https://www.gutenberg.org/cache/epub/2701/pg2701.txt\" -o mobydick.txt\n",
        "mobydick = open('mobydick.txt').read()\n",
        "\n",
        "# Create DataFrame from text\n",
        "mobydick = spark.createDataFrame([[txt]]).toDF(\"txt\")\n",
        "\n",
        "# Define Spark NLP pipeline\n",
        "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
        "pos_tagger = PerceptronModel.pretrained().setInputCols([\"document\", \"token\"]).setOutputCol(\"pos\")\n",
        "\n",
        "pipeline = Pipeline(stages=[document_assembler, tokenizer, pos_tagger])\n",
        "\n",
        "# Process the text\n",
        "model = pipeline.fit(data)\n",
        "result = model.transform(data)\n",
        "\n",
        "# Extract tokens and POS tags\n",
        "tokens_pos = result.select(explode(arrays_zip(result.token.result, result.pos.result)).alias(\"cols\")) \\\n",
        "    .select(col(\"cols\")[\"0\"].alias(\"token\"), col(\"cols\")[\"1\"].alias(\"pos\"))\n",
        "\n",
        "# Pronoun lists\n",
        "feminine_pronouns = ['she', 'her']\n",
        "masculine_pronouns = ['he', 'him']\n",
        "\n",
        "# Count pronoun occurrences by POS tag\n",
        "subject_tags = ['NN', 'NNS', 'NNP', 'NNPS', 'PRP']\n",
        "object_tags = ['PRP$', 'DT']\n",
        "\n",
        "# Filter and count\n",
        "feminine_subject_count = tokens_pos.filter((col(\"token\").isin(feminine_pronouns)) & (col(\"pos\").isin(subject_tags))).count()\n",
        "feminine_object_count = tokens_pos.filter((col(\"token\").isin(feminine_pronouns)) & (col(\"pos\").isin(object_tags))).count()\n",
        "masculine_subject_count = tokens_pos.filter((col(\"token\").isin(masculine_pronouns)) & (col(\"pos\").isin(subject_tags))).count()\n",
        "masculine_object_count = tokens_pos.filter((col(\"token\").isin(masculine_pronouns)) & (col(\"pos\").isin(object_tags))).count()\n",
        "\n",
        "# Prepare data for chi-squared test\n",
        "data = [\n",
        "    [feminine_subject_count, feminine_object_count],\n",
        "    [masculine_subject_count, masculine_object_count]\n",
        "]\n",
        "\n",
        "# Perform chi-squared test\n",
        "chi2, p, dof, ex = chi2_contingency(data)\n",
        "\n",
        "# Visualize the data\n",
        "labels = ['Feminine Subject', 'Feminine Object', 'Masculine Subject', 'Masculine Object']\n",
        "counts = [feminine_subject_count, feminine_object_count, masculine_subject_count, masculine_object_count]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(labels, counts, color=['#FF69B4', '#FF69B4', '#1E90FF', '#1E90FF'])\n",
        "plt.xlabel('Pronoun Type and Syntactic Role')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Pronoun Frequencies by Syntactic Role')\n",
        "plt.show()\n",
        "\n",
        "# Output results\n",
        "print(\"Chi-Squared Test\")\n",
        "print(f\"Chi2 Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "VtPCZQp9IhNM",
        "outputId": "37c9724e-3591-490a-8d05-bbd105978db5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1246k  100 1246k    0     0   498k      0  0:00:02  0:00:02 --:--:--  498k\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'txt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-a1cefe89f437>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Create DataFrame from text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmobydick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Define Spark NLP pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'txt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "niD-K5voIhQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-TlnNfDIhTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jnNxZTtPEKyM"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4nLTWe3TEK0u"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQcKsLqLEK3O"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}